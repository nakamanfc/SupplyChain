{"ast":null,"code":"'use strict';\n\nconst dagPb = require('@ipld/dag-pb');\n\nconst {\n  CID\n} = require('multiformats/cid');\n\nconst log = require('debug')('ipfs:mfs:core:utils:add-link');\n\nconst {\n  UnixFS\n} = require('ipfs-unixfs');\n\nconst DirSharded = require('./dir-sharded');\n\nconst {\n  updateHamtDirectory,\n  recreateHamtLevel,\n  recreateInitialHamtLevel,\n  createShard,\n  toPrefix,\n  addLinksToHamtBucket\n} = require('./hamt-utils');\n\nconst errCode = require('err-code');\n\nconst last = require('it-last');\n/**\n * @typedef {import('ipfs-unixfs').Mtime} Mtime\n * @typedef {import('multiformats/cid').CIDVersion} CIDVersion\n * @typedef {import('hamt-sharding').Bucket<any>} Bucket\n * @typedef {import('../').MfsContext} MfsContext\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {number} options.shardSplitThreshold\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {CID} [options.parentCid]\n * @param {PBNode} [options.parent]\n */\n\n\nconst addLink = async (context, options) => {\n  let parent = options.parent;\n\n  if (options.parentCid) {\n    const parentCid = CID.asCID(options.parentCid);\n\n    if (parentCid === null) {\n      throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID');\n    }\n\n    if (parentCid.code !== dagPb.code) {\n      throw errCode(new Error('Unsupported codec. Only DAG-PB is supported'), 'EINVALIDPARENTCID');\n    }\n\n    log(`Loading parent node ${parentCid}`);\n    const block = await context.repo.blocks.get(parentCid);\n    parent = dagPb.decode(block);\n  }\n\n  if (!parent) {\n    throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT');\n  }\n\n  if (!options.cid) {\n    throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID');\n  }\n\n  if (!options.name) {\n    throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME');\n  }\n\n  if (!options.size && options.size !== 0) {\n    throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE');\n  }\n\n  if (!parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addLink'), 'ERR_INVALID_PARENT');\n  }\n\n  const meta = UnixFS.unmarshal(parent.Data);\n\n  if (meta.type === 'hamt-sharded-directory') {\n    log('Adding link to sharded directory');\n    return addToShardedDirectory(context, { ...options,\n      parent\n    });\n  }\n\n  if (parent.Links.length >= options.shardSplitThreshold) {\n    log('Converting directory to sharded directory');\n    return convertToShardedDirectory(context, { ...options,\n      parent,\n      mtime: meta.mtime,\n      mode: meta.mode\n    });\n  }\n\n  log(`Adding ${options.name} (${options.cid}) to regular directory`);\n  return addToDirectory(context, { ...options,\n    parent\n  });\n};\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\n\n\nconst convertToShardedDirectory = async (context, options) => {\n  const result = await createShard(context, options.parent.Links.map(link => ({\n    name: link.Name || '',\n    size: link.Tsize || 0,\n    cid: link.Hash\n  })).concat({\n    name: options.name,\n    size: options.size,\n    cid: options.cid\n  }), options);\n  log(`Converted directory to sharded directory ${result.cid}`);\n  return result;\n};\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\n\n\nconst addToDirectory = async (context, options) => {\n  // Remove existing link if it exists\n  const parentLinks = options.parent.Links.filter(link => {\n    return link.Name !== options.name;\n  });\n  parentLinks.push({\n    Name: options.name,\n    Tsize: options.size,\n    Hash: options.cid\n  });\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addToDirectory'), 'ERR_INVALID_PARENT');\n  }\n\n  const node = UnixFS.unmarshal(options.parent.Data);\n  let data;\n\n  if (node.mtime) {\n    // Update mtime if previously set\n    const ms = Date.now();\n    const secs = Math.floor(ms / 1000);\n    node.mtime = {\n      secs: secs,\n      nsecs: (ms - secs * 1000) * 1000\n    };\n    data = node.marshal();\n  } else {\n    data = options.parent.Data;\n  }\n\n  options.parent = dagPb.prepare({\n    Data: data,\n    Links: parentLinks\n  }); // Persist the new parent PbNode\n\n  const hasher = await context.hashers.getHasher(options.hashAlg);\n  const buf = dagPb.encode(options.parent);\n  const hash = await hasher.digest(buf);\n  const cid = CID.create(options.cidVersion, dagPb.code, hash);\n\n  if (options.flush) {\n    await context.repo.blocks.put(cid, buf);\n  }\n\n  return {\n    node: options.parent,\n    cid,\n    size: buf.length\n  };\n};\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n */\n\n\nconst addToShardedDirectory = async (context, options) => {\n  const {\n    shard,\n    path\n  } = await addFileToShardedDirectory(context, options);\n  const result = await last(shard.flush(context.repo.blocks));\n\n  if (!result) {\n    throw new Error('No result from flushing shard');\n  }\n\n  const block = await context.repo.blocks.get(result.cid);\n  const node = dagPb.decode(block); // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n\n  const parentLinks = options.parent.Links.filter(link => {\n    // TODO vmx 2021-03-31: Check that there cannot be multiple ones matching\n    // Remove the old link\n    return (link.Name || '').substring(0, 2) !== path[0].prefix;\n  });\n  const newLink = node.Links.find(link => (link.Name || '').substring(0, 2) === path[0].prefix);\n\n  if (!newLink) {\n    throw new Error(`No link found with prefix ${path[0].prefix}`);\n  }\n\n  parentLinks.push(newLink);\n  return updateHamtDirectory(context, parentLinks, path[0].bucket, options);\n};\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n */\n\n\nconst addFileToShardedDirectory = async (context, options) => {\n  const file = {\n    name: options.name,\n    cid: options.cid,\n    size: options.size\n  };\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addFileToShardedDirectory'), 'ERR_INVALID_PARENT');\n  } // start at the root bucket and descend, loading nodes as we go\n\n\n  const rootBucket = await recreateInitialHamtLevel(options.parent.Links);\n  const node = UnixFS.unmarshal(options.parent.Data);\n  const shard = new DirSharded({\n    root: true,\n    dir: true,\n    parent: undefined,\n    parentKey: undefined,\n    path: '',\n    dirty: true,\n    flat: false,\n    mode: node.mode\n  }, options);\n  shard._bucket = rootBucket;\n\n  if (node.mtime) {\n    // update mtime if previously set\n    shard.mtime = {\n      secs: Math.round(Date.now() / 1000)\n    };\n  } // load subshards until the bucket & position no longer changes\n\n\n  const position = await rootBucket._findNewBucketAndPos(file.name);\n  const path = toBucketPath(position);\n  path[0].node = options.parent;\n  let index = 0;\n\n  while (index < path.length) {\n    const segment = path[index];\n    index++;\n    const node = segment.node;\n\n    if (!node) {\n      throw new Error('Segment had no node');\n    }\n\n    const link = node.Links.find(link => (link.Name || '').substring(0, 2) === segment.prefix);\n\n    if (!link) {\n      // prefix is new, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be added`);\n      index = path.length;\n      break;\n    }\n\n    if (link.Name === `${segment.prefix}${file.name}`) {\n      // file already existed, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be replaced`);\n      index = path.length;\n      break;\n    }\n\n    if ((link.Name || '').length > 2) {\n      // another file had the same prefix, will be replaced with a subshard\n      log(`Link ${link.Name} ${link.Hash} will be replaced with a subshard`);\n      index = path.length;\n      break;\n    } // load sub-shard\n\n\n    log(`Found subshard ${segment.prefix}`);\n    const block = await context.repo.blocks.get(link.Hash);\n    const subShard = dagPb.decode(block); // subshard hasn't been loaded, descend to the next level of the HAMT\n\n    if (!path[index]) {\n      log(`Loaded new subshard ${segment.prefix}`);\n      await recreateHamtLevel(subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16));\n      const position = await rootBucket._findNewBucketAndPos(file.name);\n      path.push({\n        bucket: position.bucket,\n        prefix: toPrefix(position.pos),\n        node: subShard\n      });\n      break;\n    }\n\n    const nextSegment = path[index]; // add next levels worth of links to bucket\n\n    await addLinksToHamtBucket(subShard.Links, nextSegment.bucket, rootBucket);\n    nextSegment.node = subShard;\n  } // finally add the new file into the shard\n\n\n  await shard._bucket.put(file.name, {\n    size: file.size,\n    cid: file.cid\n  });\n  return {\n    shard,\n    path\n  };\n};\n/**\n * @param {{ pos: number, bucket: Bucket }} position\n * @returns {{ bucket: Bucket, prefix: string, node?: PBNode }[]}\n */\n\n\nconst toBucketPath = position => {\n  const path = [{\n    bucket: position.bucket,\n    prefix: toPrefix(position.pos)\n  }];\n  let bucket = position.bucket._parent;\n  let positionInBucket = position.bucket._posAtParent;\n\n  while (bucket) {\n    path.push({\n      bucket,\n      prefix: toPrefix(positionInBucket)\n    });\n    positionInBucket = bucket._posAtParent;\n    bucket = bucket._parent;\n  }\n\n  path.reverse();\n  return path;\n};\n\nmodule.exports = addLink;","map":{"version":3,"sources":["C:/Users/user/mew-supplychain/front-end/node_modules/ipfs-core/src/components/files/utils/add-link.js"],"names":["dagPb","require","CID","log","UnixFS","DirSharded","updateHamtDirectory","recreateHamtLevel","recreateInitialHamtLevel","createShard","toPrefix","addLinksToHamtBucket","errCode","last","addLink","context","options","parent","parentCid","asCID","Error","code","block","repo","blocks","get","decode","cid","name","size","Data","meta","unmarshal","type","addToShardedDirectory","Links","length","shardSplitThreshold","convertToShardedDirectory","mtime","mode","addToDirectory","result","map","link","Name","Tsize","Hash","concat","parentLinks","filter","push","node","data","ms","Date","now","secs","Math","floor","nsecs","marshal","prepare","hasher","hashers","getHasher","hashAlg","buf","encode","hash","digest","create","cidVersion","flush","put","shard","path","addFileToShardedDirectory","substring","prefix","newLink","find","bucket","file","rootBucket","root","dir","undefined","parentKey","dirty","flat","_bucket","round","position","_findNewBucketAndPos","toBucketPath","index","segment","subShard","parseInt","pos","nextSegment","_parent","positionInBucket","_posAtParent","reverse","module","exports"],"mappings":"AAAA;;AAEA,MAAMA,KAAK,GAAGC,OAAO,CAAC,cAAD,CAArB;;AACA,MAAM;AAAEC,EAAAA;AAAF,IAAUD,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAME,GAAG,GAAGF,OAAO,CAAC,OAAD,CAAP,CAAiB,8BAAjB,CAAZ;;AACA,MAAM;AAAEG,EAAAA;AAAF,IAAaH,OAAO,CAAC,aAAD,CAA1B;;AACA,MAAMI,UAAU,GAAGJ,OAAO,CAAC,eAAD,CAA1B;;AACA,MAAM;AACJK,EAAAA,mBADI;AAEJC,EAAAA,iBAFI;AAGJC,EAAAA,wBAHI;AAIJC,EAAAA,WAJI;AAKJC,EAAAA,QALI;AAMJC,EAAAA;AANI,IAOFV,OAAO,CAAC,cAAD,CAPX;;AAQA,MAAMW,OAAO,GAAGX,OAAO,CAAC,UAAD,CAAvB;;AACA,MAAMY,IAAI,GAAGZ,OAAO,CAAC,SAAD,CAApB;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMa,OAAO,GAAG,OAAOC,OAAP,EAAgBC,OAAhB,KAA4B;AAC1C,MAAIC,MAAM,GAAGD,OAAO,CAACC,MAArB;;AAEA,MAAID,OAAO,CAACE,SAAZ,EAAuB;AACrB,UAAMA,SAAS,GAAGhB,GAAG,CAACiB,KAAJ,CAAUH,OAAO,CAACE,SAAlB,CAAlB;;AACA,QAAIA,SAAS,KAAK,IAAlB,EAAwB;AACtB,YAAMN,OAAO,CAAC,IAAIQ,KAAJ,CAAU,+BAAV,CAAD,EAA6C,mBAA7C,CAAb;AACD;;AAED,QAAIF,SAAS,CAACG,IAAV,KAAmBrB,KAAK,CAACqB,IAA7B,EAAmC;AACjC,YAAMT,OAAO,CAAC,IAAIQ,KAAJ,CAAU,6CAAV,CAAD,EAA2D,mBAA3D,CAAb;AACD;;AAEDjB,IAAAA,GAAG,CAAE,uBAAsBe,SAAU,EAAlC,CAAH;AACA,UAAMI,KAAK,GAAG,MAAMP,OAAO,CAACQ,IAAR,CAAaC,MAAb,CAAoBC,GAApB,CAAwBP,SAAxB,CAApB;AACAD,IAAAA,MAAM,GAAGjB,KAAK,CAAC0B,MAAN,CAAaJ,KAAb,CAAT;AACD;;AAED,MAAI,CAACL,MAAL,EAAa;AACX,UAAML,OAAO,CAAC,IAAIQ,KAAJ,CAAU,yCAAV,CAAD,EAAuD,gBAAvD,CAAb;AACD;;AAED,MAAI,CAACJ,OAAO,CAACW,GAAb,EAAkB;AAChB,UAAMf,OAAO,CAAC,IAAIQ,KAAJ,CAAU,gCAAV,CAAD,EAA8C,kBAA9C,CAAb;AACD;;AAED,MAAI,CAACJ,OAAO,CAACY,IAAb,EAAmB;AACjB,UAAMhB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,iCAAV,CAAD,EAA+C,mBAA/C,CAAb;AACD;;AAED,MAAI,CAACJ,OAAO,CAACa,IAAT,IAAiBb,OAAO,CAACa,IAAR,KAAiB,CAAtC,EAAyC;AACvC,UAAMjB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,iCAAV,CAAD,EAA+C,mBAA/C,CAAb;AACD;;AAED,MAAI,CAACH,MAAM,CAACa,IAAZ,EAAkB;AAChB,UAAMlB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,4CAAV,CAAD,EAA0D,oBAA1D,CAAb;AACD;;AAED,QAAMW,IAAI,GAAG3B,MAAM,CAAC4B,SAAP,CAAiBf,MAAM,CAACa,IAAxB,CAAb;;AAEA,MAAIC,IAAI,CAACE,IAAL,KAAc,wBAAlB,EAA4C;AAC1C9B,IAAAA,GAAG,CAAC,kCAAD,CAAH;AAEA,WAAO+B,qBAAqB,CAACnB,OAAD,EAAU,EACpC,GAAGC,OADiC;AAEpCC,MAAAA;AAFoC,KAAV,CAA5B;AAID;;AAED,MAAIA,MAAM,CAACkB,KAAP,CAAaC,MAAb,IAAuBpB,OAAO,CAACqB,mBAAnC,EAAwD;AACtDlC,IAAAA,GAAG,CAAC,2CAAD,CAAH;AAEA,WAAOmC,yBAAyB,CAACvB,OAAD,EAAU,EACxC,GAAGC,OADqC;AAExCC,MAAAA,MAFwC;AAGxCsB,MAAAA,KAAK,EAAER,IAAI,CAACQ,KAH4B;AAIxCC,MAAAA,IAAI,EAAET,IAAI,CAACS;AAJ6B,KAAV,CAAhC;AAMD;;AAEDrC,EAAAA,GAAG,CAAE,UAASa,OAAO,CAACY,IAAK,KAAIZ,OAAO,CAACW,GAAI,wBAAxC,CAAH;AAEA,SAAOc,cAAc,CAAC1B,OAAD,EAAU,EAC7B,GAAGC,OAD0B;AAE7BC,IAAAA;AAF6B,GAAV,CAArB;AAID,CAlED;AAoEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMqB,yBAAyB,GAAG,OAAOvB,OAAP,EAAgBC,OAAhB,KAA4B;AAC5D,QAAM0B,MAAM,GAAG,MAAMjC,WAAW,CAACM,OAAD,EAAUC,OAAO,CAACC,MAAR,CAAekB,KAAf,CAAqBQ,GAArB,CAAyBC,IAAI,KAAK;AAC1EhB,IAAAA,IAAI,EAAGgB,IAAI,CAACC,IAAL,IAAa,EADsD;AAE1EhB,IAAAA,IAAI,EAAEe,IAAI,CAACE,KAAL,IAAc,CAFsD;AAG1EnB,IAAAA,GAAG,EAAEiB,IAAI,CAACG;AAHgE,GAAL,CAA7B,EAItCC,MAJsC,CAI/B;AACTpB,IAAAA,IAAI,EAAEZ,OAAO,CAACY,IADL;AAETC,IAAAA,IAAI,EAAEb,OAAO,CAACa,IAFL;AAGTF,IAAAA,GAAG,EAAEX,OAAO,CAACW;AAHJ,GAJ+B,CAAV,EAQ5BX,OAR4B,CAAhC;AAUAb,EAAAA,GAAG,CAAE,4CAA2CuC,MAAM,CAACf,GAAI,EAAxD,CAAH;AAEA,SAAOe,MAAP;AACD,CAdD;AAgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMD,cAAc,GAAG,OAAO1B,OAAP,EAAgBC,OAAhB,KAA4B;AACjD;AACA,QAAMiC,WAAW,GAAGjC,OAAO,CAACC,MAAR,CAAekB,KAAf,CAAqBe,MAArB,CAA6BN,IAAD,IAAU;AACxD,WAAOA,IAAI,CAACC,IAAL,KAAc7B,OAAO,CAACY,IAA7B;AACD,GAFmB,CAApB;AAGAqB,EAAAA,WAAW,CAACE,IAAZ,CAAiB;AACfN,IAAAA,IAAI,EAAE7B,OAAO,CAACY,IADC;AAEfkB,IAAAA,KAAK,EAAE9B,OAAO,CAACa,IAFA;AAGfkB,IAAAA,IAAI,EAAE/B,OAAO,CAACW;AAHC,GAAjB;;AAMA,MAAI,CAACX,OAAO,CAACC,MAAR,CAAea,IAApB,EAA0B;AACxB,UAAMlB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,mDAAV,CAAD,EAAiE,oBAAjE,CAAb;AACD;;AAED,QAAMgC,IAAI,GAAGhD,MAAM,CAAC4B,SAAP,CAAiBhB,OAAO,CAACC,MAAR,CAAea,IAAhC,CAAb;AAEA,MAAIuB,IAAJ;;AACA,MAAID,IAAI,CAACb,KAAT,EAAgB;AACd;AACA,UAAMe,EAAE,GAAGC,IAAI,CAACC,GAAL,EAAX;AACA,UAAMC,IAAI,GAAGC,IAAI,CAACC,KAAL,CAAWL,EAAE,GAAG,IAAhB,CAAb;AAEAF,IAAAA,IAAI,CAACb,KAAL,GAAa;AACXkB,MAAAA,IAAI,EAAEA,IADK;AAEXG,MAAAA,KAAK,EAAE,CAACN,EAAE,GAAIG,IAAI,GAAG,IAAd,IAAuB;AAFnB,KAAb;AAKAJ,IAAAA,IAAI,GAAGD,IAAI,CAACS,OAAL,EAAP;AACD,GAXD,MAWO;AACLR,IAAAA,IAAI,GAAGrC,OAAO,CAACC,MAAR,CAAea,IAAtB;AACD;;AACDd,EAAAA,OAAO,CAACC,MAAR,GAAiBjB,KAAK,CAAC8D,OAAN,CAAc;AAC7BhC,IAAAA,IAAI,EAAEuB,IADuB;AAE7BlB,IAAAA,KAAK,EAAEc;AAFsB,GAAd,CAAjB,CAhCiD,CAqCjD;;AACA,QAAMc,MAAM,GAAG,MAAMhD,OAAO,CAACiD,OAAR,CAAgBC,SAAhB,CAA0BjD,OAAO,CAACkD,OAAlC,CAArB;AACA,QAAMC,GAAG,GAAGnE,KAAK,CAACoE,MAAN,CAAapD,OAAO,CAACC,MAArB,CAAZ;AACA,QAAMoD,IAAI,GAAG,MAAMN,MAAM,CAACO,MAAP,CAAcH,GAAd,CAAnB;AACA,QAAMxC,GAAG,GAAGzB,GAAG,CAACqE,MAAJ,CAAWvD,OAAO,CAACwD,UAAnB,EAA+BxE,KAAK,CAACqB,IAArC,EAA2CgD,IAA3C,CAAZ;;AAEA,MAAIrD,OAAO,CAACyD,KAAZ,EAAmB;AACjB,UAAM1D,OAAO,CAACQ,IAAR,CAAaC,MAAb,CAAoBkD,GAApB,CAAwB/C,GAAxB,EAA6BwC,GAA7B,CAAN;AACD;;AAED,SAAO;AACLf,IAAAA,IAAI,EAAEpC,OAAO,CAACC,MADT;AAELU,IAAAA,GAFK;AAGLE,IAAAA,IAAI,EAAEsC,GAAG,CAAC/B;AAHL,GAAP;AAKD,CApDD;AAsDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMF,qBAAqB,GAAG,OAAOnB,OAAP,EAAgBC,OAAhB,KAA4B;AACxD,QAAM;AACJ2D,IAAAA,KADI;AACGC,IAAAA;AADH,MAEF,MAAMC,yBAAyB,CAAC9D,OAAD,EAAUC,OAAV,CAFnC;AAGA,QAAM0B,MAAM,GAAG,MAAM7B,IAAI,CAAC8D,KAAK,CAACF,KAAN,CAAY1D,OAAO,CAACQ,IAAR,CAAaC,MAAzB,CAAD,CAAzB;;AAEA,MAAI,CAACkB,MAAL,EAAa;AACX,UAAM,IAAItB,KAAJ,CAAU,+BAAV,CAAN;AACD;;AAED,QAAME,KAAK,GAAG,MAAMP,OAAO,CAACQ,IAAR,CAAaC,MAAb,CAAoBC,GAApB,CAAwBiB,MAAM,CAACf,GAA/B,CAApB;AACA,QAAMyB,IAAI,GAAGpD,KAAK,CAAC0B,MAAN,CAAaJ,KAAb,CAAb,CAXwD,CAaxD;;AACA,QAAM2B,WAAW,GAAGjC,OAAO,CAACC,MAAR,CAAekB,KAAf,CAAqBe,MAArB,CAA6BN,IAAD,IAAU;AACxD;AACA;AACA,WAAO,CAACA,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBiC,SAAlB,CAA4B,CAA5B,EAA+B,CAA/B,MAAsCF,IAAI,CAAC,CAAD,CAAJ,CAAQG,MAArD;AACD,GAJmB,CAApB;AAMA,QAAMC,OAAO,GAAG5B,IAAI,CAACjB,KAAL,CACb8C,IADa,CACRrC,IAAI,IAAI,CAACA,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBiC,SAAlB,CAA4B,CAA5B,EAA+B,CAA/B,MAAsCF,IAAI,CAAC,CAAD,CAAJ,CAAQG,MAD9C,CAAhB;;AAGA,MAAI,CAACC,OAAL,EAAc;AACZ,UAAM,IAAI5D,KAAJ,CAAW,6BAA4BwD,IAAI,CAAC,CAAD,CAAJ,CAAQG,MAAO,EAAtD,CAAN;AACD;;AAED9B,EAAAA,WAAW,CAACE,IAAZ,CAAiB6B,OAAjB;AAEA,SAAO1E,mBAAmB,CAACS,OAAD,EAAUkC,WAAV,EAAuB2B,IAAI,CAAC,CAAD,CAAJ,CAAQM,MAA/B,EAAuClE,OAAvC,CAA1B;AACD,CA9BD;AAgCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAM6D,yBAAyB,GAAG,OAAO9D,OAAP,EAAgBC,OAAhB,KAA4B;AAC5D,QAAMmE,IAAI,GAAG;AACXvD,IAAAA,IAAI,EAAEZ,OAAO,CAACY,IADH;AAEXD,IAAAA,GAAG,EAAEX,OAAO,CAACW,GAFF;AAGXE,IAAAA,IAAI,EAAEb,OAAO,CAACa;AAHH,GAAb;;AAMA,MAAI,CAACb,OAAO,CAACC,MAAR,CAAea,IAApB,EAA0B;AACxB,UAAMlB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,8DAAV,CAAD,EAA4E,oBAA5E,CAAb;AACD,GAT2D,CAW5D;;;AACA,QAAMgE,UAAU,GAAG,MAAM5E,wBAAwB,CAACQ,OAAO,CAACC,MAAR,CAAekB,KAAhB,CAAjD;AACA,QAAMiB,IAAI,GAAGhD,MAAM,CAAC4B,SAAP,CAAiBhB,OAAO,CAACC,MAAR,CAAea,IAAhC,CAAb;AAEA,QAAM6C,KAAK,GAAG,IAAItE,UAAJ,CAAe;AAC3BgF,IAAAA,IAAI,EAAE,IADqB;AAE3BC,IAAAA,GAAG,EAAE,IAFsB;AAG3BrE,IAAAA,MAAM,EAAEsE,SAHmB;AAI3BC,IAAAA,SAAS,EAAED,SAJgB;AAK3BX,IAAAA,IAAI,EAAE,EALqB;AAM3Ba,IAAAA,KAAK,EAAE,IANoB;AAO3BC,IAAAA,IAAI,EAAE,KAPqB;AAQ3BlD,IAAAA,IAAI,EAAEY,IAAI,CAACZ;AARgB,GAAf,EASXxB,OATW,CAAd;AAUA2D,EAAAA,KAAK,CAACgB,OAAN,GAAgBP,UAAhB;;AAEA,MAAIhC,IAAI,CAACb,KAAT,EAAgB;AACd;AACAoC,IAAAA,KAAK,CAACpC,KAAN,GAAc;AACZkB,MAAAA,IAAI,EAAEC,IAAI,CAACkC,KAAL,CAAWrC,IAAI,CAACC,GAAL,KAAa,IAAxB;AADM,KAAd;AAGD,GAhC2D,CAkC5D;;;AACA,QAAMqC,QAAQ,GAAG,MAAMT,UAAU,CAACU,oBAAX,CAAgCX,IAAI,CAACvD,IAArC,CAAvB;AACA,QAAMgD,IAAI,GAAGmB,YAAY,CAACF,QAAD,CAAzB;AACAjB,EAAAA,IAAI,CAAC,CAAD,CAAJ,CAAQxB,IAAR,GAAepC,OAAO,CAACC,MAAvB;AACA,MAAI+E,KAAK,GAAG,CAAZ;;AAEA,SAAOA,KAAK,GAAGpB,IAAI,CAACxC,MAApB,EAA4B;AAC1B,UAAM6D,OAAO,GAAGrB,IAAI,CAACoB,KAAD,CAApB;AACAA,IAAAA,KAAK;AACL,UAAM5C,IAAI,GAAG6C,OAAO,CAAC7C,IAArB;;AAEA,QAAI,CAACA,IAAL,EAAW;AACT,YAAM,IAAIhC,KAAJ,CAAU,qBAAV,CAAN;AACD;;AAED,UAAMwB,IAAI,GAAGQ,IAAI,CAACjB,KAAL,CACV8C,IADU,CACLrC,IAAI,IAAI,CAACA,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBiC,SAAlB,CAA4B,CAA5B,EAA+B,CAA/B,MAAsCmB,OAAO,CAAClB,MADjD,CAAb;;AAGA,QAAI,CAACnC,IAAL,EAAW;AACT;AACAzC,MAAAA,GAAG,CAAE,QAAO8F,OAAO,CAAClB,MAAO,GAAEI,IAAI,CAACvD,IAAK,gBAApC,CAAH;AACAoE,MAAAA,KAAK,GAAGpB,IAAI,CAACxC,MAAb;AAEA;AACD;;AAED,QAAIQ,IAAI,CAACC,IAAL,KAAe,GAAEoD,OAAO,CAAClB,MAAO,GAAEI,IAAI,CAACvD,IAAK,EAAhD,EAAmD;AACjD;AACAzB,MAAAA,GAAG,CAAE,QAAO8F,OAAO,CAAClB,MAAO,GAAEI,IAAI,CAACvD,IAAK,mBAApC,CAAH;AACAoE,MAAAA,KAAK,GAAGpB,IAAI,CAACxC,MAAb;AAEA;AACD;;AAED,QAAI,CAACQ,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBT,MAAlB,GAA2B,CAA/B,EAAkC;AAChC;AACAjC,MAAAA,GAAG,CAAE,QAAOyC,IAAI,CAACC,IAAK,IAAGD,IAAI,CAACG,IAAK,mCAAhC,CAAH;AACAiD,MAAAA,KAAK,GAAGpB,IAAI,CAACxC,MAAb;AAEA;AACD,KAlCyB,CAoC1B;;;AACAjC,IAAAA,GAAG,CAAE,kBAAiB8F,OAAO,CAAClB,MAAO,EAAlC,CAAH;AACA,UAAMzD,KAAK,GAAG,MAAMP,OAAO,CAACQ,IAAR,CAAaC,MAAb,CAAoBC,GAApB,CAAwBmB,IAAI,CAACG,IAA7B,CAApB;AACA,UAAMmD,QAAQ,GAAGlG,KAAK,CAAC0B,MAAN,CAAaJ,KAAb,CAAjB,CAvC0B,CAyC1B;;AACA,QAAI,CAACsD,IAAI,CAACoB,KAAD,CAAT,EAAkB;AAChB7F,MAAAA,GAAG,CAAE,uBAAsB8F,OAAO,CAAClB,MAAO,EAAvC,CAAH;AACA,YAAMxE,iBAAiB,CAAC2F,QAAQ,CAAC/D,KAAV,EAAiBiD,UAAjB,EAA6Ba,OAAO,CAACf,MAArC,EAA6CiB,QAAQ,CAACF,OAAO,CAAClB,MAAT,EAAiB,EAAjB,CAArD,CAAvB;AAEA,YAAMc,QAAQ,GAAG,MAAMT,UAAU,CAACU,oBAAX,CAAgCX,IAAI,CAACvD,IAArC,CAAvB;AAEAgD,MAAAA,IAAI,CAACzB,IAAL,CAAU;AACR+B,QAAAA,MAAM,EAAEW,QAAQ,CAACX,MADT;AAERH,QAAAA,MAAM,EAAErE,QAAQ,CAACmF,QAAQ,CAACO,GAAV,CAFR;AAGRhD,QAAAA,IAAI,EAAE8C;AAHE,OAAV;AAMA;AACD;;AAED,UAAMG,WAAW,GAAGzB,IAAI,CAACoB,KAAD,CAAxB,CAzD0B,CA2D1B;;AACA,UAAMrF,oBAAoB,CAACuF,QAAQ,CAAC/D,KAAV,EAAiBkE,WAAW,CAACnB,MAA7B,EAAqCE,UAArC,CAA1B;AAEAiB,IAAAA,WAAW,CAACjD,IAAZ,GAAmB8C,QAAnB;AACD,GAvG2D,CAyG5D;;;AACA,QAAMvB,KAAK,CAACgB,OAAN,CAAcjB,GAAd,CAAkBS,IAAI,CAACvD,IAAvB,EAA6B;AACjCC,IAAAA,IAAI,EAAEsD,IAAI,CAACtD,IADsB;AAEjCF,IAAAA,GAAG,EAAEwD,IAAI,CAACxD;AAFuB,GAA7B,CAAN;AAKA,SAAO;AACLgD,IAAAA,KADK;AACEC,IAAAA;AADF,GAAP;AAGD,CAlHD;AAoHA;AACA;AACA;AACA;;;AACA,MAAMmB,YAAY,GAAIF,QAAD,IAAc;AACjC,QAAMjB,IAAI,GAAG,CAAC;AACZM,IAAAA,MAAM,EAAEW,QAAQ,CAACX,MADL;AAEZH,IAAAA,MAAM,EAAErE,QAAQ,CAACmF,QAAQ,CAACO,GAAV;AAFJ,GAAD,CAAb;AAKA,MAAIlB,MAAM,GAAGW,QAAQ,CAACX,MAAT,CAAgBoB,OAA7B;AACA,MAAIC,gBAAgB,GAAGV,QAAQ,CAACX,MAAT,CAAgBsB,YAAvC;;AAEA,SAAOtB,MAAP,EAAe;AACbN,IAAAA,IAAI,CAACzB,IAAL,CAAU;AACR+B,MAAAA,MADQ;AAERH,MAAAA,MAAM,EAAErE,QAAQ,CAAC6F,gBAAD;AAFR,KAAV;AAKAA,IAAAA,gBAAgB,GAAGrB,MAAM,CAACsB,YAA1B;AACAtB,IAAAA,MAAM,GAAGA,MAAM,CAACoB,OAAhB;AACD;;AAED1B,EAAAA,IAAI,CAAC6B,OAAL;AAEA,SAAO7B,IAAP;AACD,CAtBD;;AAwBA8B,MAAM,CAACC,OAAP,GAAiB7F,OAAjB","sourcesContent":["'use strict'\n\nconst dagPb = require('@ipld/dag-pb')\nconst { CID } = require('multiformats/cid')\nconst log = require('debug')('ipfs:mfs:core:utils:add-link')\nconst { UnixFS } = require('ipfs-unixfs')\nconst DirSharded = require('./dir-sharded')\nconst {\n  updateHamtDirectory,\n  recreateHamtLevel,\n  recreateInitialHamtLevel,\n  createShard,\n  toPrefix,\n  addLinksToHamtBucket\n} = require('./hamt-utils')\nconst errCode = require('err-code')\nconst last = require('it-last')\n\n/**\n * @typedef {import('ipfs-unixfs').Mtime} Mtime\n * @typedef {import('multiformats/cid').CIDVersion} CIDVersion\n * @typedef {import('hamt-sharding').Bucket<any>} Bucket\n * @typedef {import('../').MfsContext} MfsContext\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {number} options.shardSplitThreshold\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {CID} [options.parentCid]\n * @param {PBNode} [options.parent]\n */\nconst addLink = async (context, options) => {\n  let parent = options.parent\n\n  if (options.parentCid) {\n    const parentCid = CID.asCID(options.parentCid)\n    if (parentCid === null) {\n      throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID')\n    }\n\n    if (parentCid.code !== dagPb.code) {\n      throw errCode(new Error('Unsupported codec. Only DAG-PB is supported'), 'EINVALIDPARENTCID')\n    }\n\n    log(`Loading parent node ${parentCid}`)\n    const block = await context.repo.blocks.get(parentCid)\n    parent = dagPb.decode(block)\n  }\n\n  if (!parent) {\n    throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT')\n  }\n\n  if (!options.cid) {\n    throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID')\n  }\n\n  if (!options.name) {\n    throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME')\n  }\n\n  if (!options.size && options.size !== 0) {\n    throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE')\n  }\n\n  if (!parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addLink'), 'ERR_INVALID_PARENT')\n  }\n\n  const meta = UnixFS.unmarshal(parent.Data)\n\n  if (meta.type === 'hamt-sharded-directory') {\n    log('Adding link to sharded directory')\n\n    return addToShardedDirectory(context, {\n      ...options,\n      parent\n    })\n  }\n\n  if (parent.Links.length >= options.shardSplitThreshold) {\n    log('Converting directory to sharded directory')\n\n    return convertToShardedDirectory(context, {\n      ...options,\n      parent,\n      mtime: meta.mtime,\n      mode: meta.mode\n    })\n  }\n\n  log(`Adding ${options.name} (${options.cid}) to regular directory`)\n\n  return addToDirectory(context, {\n    ...options,\n    parent\n  })\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\nconst convertToShardedDirectory = async (context, options) => {\n  const result = await createShard(context, options.parent.Links.map(link => ({\n    name: (link.Name || ''),\n    size: link.Tsize || 0,\n    cid: link.Hash\n  })).concat({\n    name: options.name,\n    size: options.size,\n    cid: options.cid\n  }), options)\n\n  log(`Converted directory to sharded directory ${result.cid}`)\n\n  return result\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\nconst addToDirectory = async (context, options) => {\n  // Remove existing link if it exists\n  const parentLinks = options.parent.Links.filter((link) => {\n    return link.Name !== options.name\n  })\n  parentLinks.push({\n    Name: options.name,\n    Tsize: options.size,\n    Hash: options.cid\n  })\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addToDirectory'), 'ERR_INVALID_PARENT')\n  }\n\n  const node = UnixFS.unmarshal(options.parent.Data)\n\n  let data\n  if (node.mtime) {\n    // Update mtime if previously set\n    const ms = Date.now()\n    const secs = Math.floor(ms / 1000)\n\n    node.mtime = {\n      secs: secs,\n      nsecs: (ms - (secs * 1000)) * 1000\n    }\n\n    data = node.marshal()\n  } else {\n    data = options.parent.Data\n  }\n  options.parent = dagPb.prepare({\n    Data: data,\n    Links: parentLinks\n  })\n\n  // Persist the new parent PbNode\n  const hasher = await context.hashers.getHasher(options.hashAlg)\n  const buf = dagPb.encode(options.parent)\n  const hash = await hasher.digest(buf)\n  const cid = CID.create(options.cidVersion, dagPb.code, hash)\n\n  if (options.flush) {\n    await context.repo.blocks.put(cid, buf)\n  }\n\n  return {\n    node: options.parent,\n    cid,\n    size: buf.length\n  }\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n */\nconst addToShardedDirectory = async (context, options) => {\n  const {\n    shard, path\n  } = await addFileToShardedDirectory(context, options)\n  const result = await last(shard.flush(context.repo.blocks))\n\n  if (!result) {\n    throw new Error('No result from flushing shard')\n  }\n\n  const block = await context.repo.blocks.get(result.cid)\n  const node = dagPb.decode(block)\n\n  // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n  const parentLinks = options.parent.Links.filter((link) => {\n    // TODO vmx 2021-03-31: Check that there cannot be multiple ones matching\n    // Remove the old link\n    return (link.Name || '').substring(0, 2) !== path[0].prefix\n  })\n\n  const newLink = node.Links\n    .find(link => (link.Name || '').substring(0, 2) === path[0].prefix)\n\n  if (!newLink) {\n    throw new Error(`No link found with prefix ${path[0].prefix}`)\n  }\n\n  parentLinks.push(newLink)\n\n  return updateHamtDirectory(context, parentLinks, path[0].bucket, options)\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n */\nconst addFileToShardedDirectory = async (context, options) => {\n  const file = {\n    name: options.name,\n    cid: options.cid,\n    size: options.size\n  }\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addFileToShardedDirectory'), 'ERR_INVALID_PARENT')\n  }\n\n  // start at the root bucket and descend, loading nodes as we go\n  const rootBucket = await recreateInitialHamtLevel(options.parent.Links)\n  const node = UnixFS.unmarshal(options.parent.Data)\n\n  const shard = new DirSharded({\n    root: true,\n    dir: true,\n    parent: undefined,\n    parentKey: undefined,\n    path: '',\n    dirty: true,\n    flat: false,\n    mode: node.mode\n  }, options)\n  shard._bucket = rootBucket\n\n  if (node.mtime) {\n    // update mtime if previously set\n    shard.mtime = {\n      secs: Math.round(Date.now() / 1000)\n    }\n  }\n\n  // load subshards until the bucket & position no longer changes\n  const position = await rootBucket._findNewBucketAndPos(file.name)\n  const path = toBucketPath(position)\n  path[0].node = options.parent\n  let index = 0\n\n  while (index < path.length) {\n    const segment = path[index]\n    index++\n    const node = segment.node\n\n    if (!node) {\n      throw new Error('Segment had no node')\n    }\n\n    const link = node.Links\n      .find(link => (link.Name || '').substring(0, 2) === segment.prefix)\n\n    if (!link) {\n      // prefix is new, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be added`)\n      index = path.length\n\n      break\n    }\n\n    if (link.Name === `${segment.prefix}${file.name}`) {\n      // file already existed, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be replaced`)\n      index = path.length\n\n      break\n    }\n\n    if ((link.Name || '').length > 2) {\n      // another file had the same prefix, will be replaced with a subshard\n      log(`Link ${link.Name} ${link.Hash} will be replaced with a subshard`)\n      index = path.length\n\n      break\n    }\n\n    // load sub-shard\n    log(`Found subshard ${segment.prefix}`)\n    const block = await context.repo.blocks.get(link.Hash)\n    const subShard = dagPb.decode(block)\n\n    // subshard hasn't been loaded, descend to the next level of the HAMT\n    if (!path[index]) {\n      log(`Loaded new subshard ${segment.prefix}`)\n      await recreateHamtLevel(subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16))\n\n      const position = await rootBucket._findNewBucketAndPos(file.name)\n\n      path.push({\n        bucket: position.bucket,\n        prefix: toPrefix(position.pos),\n        node: subShard\n      })\n\n      break\n    }\n\n    const nextSegment = path[index]\n\n    // add next levels worth of links to bucket\n    await addLinksToHamtBucket(subShard.Links, nextSegment.bucket, rootBucket)\n\n    nextSegment.node = subShard\n  }\n\n  // finally add the new file into the shard\n  await shard._bucket.put(file.name, {\n    size: file.size,\n    cid: file.cid\n  })\n\n  return {\n    shard, path\n  }\n}\n\n/**\n * @param {{ pos: number, bucket: Bucket }} position\n * @returns {{ bucket: Bucket, prefix: string, node?: PBNode }[]}\n */\nconst toBucketPath = (position) => {\n  const path = [{\n    bucket: position.bucket,\n    prefix: toPrefix(position.pos)\n  }]\n\n  let bucket = position.bucket._parent\n  let positionInBucket = position.bucket._posAtParent\n\n  while (bucket) {\n    path.push({\n      bucket,\n      prefix: toPrefix(positionInBucket)\n    })\n\n    positionInBucket = bucket._posAtParent\n    bucket = bucket._parent\n  }\n\n  path.reverse()\n\n  return path\n}\n\nmodule.exports = addLink\n"]},"metadata":{},"sourceType":"script"}