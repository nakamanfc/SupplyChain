{"ast":null,"code":"'use strict';\n\nvar dagPb = require('@ipld/dag-pb');\n\nvar ipfsUnixfs = require('ipfs-unixfs');\n\nvar dir = require('./dir.js');\n\nvar persist = require('./utils/persist.js');\n\nvar hamtSharding = require('hamt-sharding');\n\nclass DirSharded extends dir {\n  constructor(props, options) {\n    super(props, options);\n    this._bucket = hamtSharding.createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n\n  async put(name, value) {\n    await this._bucket.put(name, value);\n  }\n\n  get(name) {\n    return this._bucket.get(name);\n  }\n\n  childCount() {\n    return this._bucket.leafCount();\n  }\n\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n\n  async *eachChildSeries() {\n    for await (const {\n      key,\n      value\n    } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      };\n    }\n  }\n\n  async *flush(blockstore) {\n    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {\n      yield { ...entry,\n        path: this.path\n      };\n    }\n  }\n\n}\n\nasync function* flush(bucket, blockstore, shardRoot, options) {\n  const children = bucket._children;\n  const links = [];\n  let childrenSize = 0;\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i);\n\n    if (!child) {\n      continue;\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n\n    if (child instanceof hamtSharding.Bucket) {\n      let shard;\n\n      for await (const subShard of await flush(child, blockstore, null, options)) {\n        shard = subShard;\n      }\n\n      if (!shard) {\n        throw new Error('Could not flush sharded directory, no subshard found');\n      }\n\n      links.push({\n        Name: labelPrefix,\n        Tsize: shard.size,\n        Hash: shard.cid\n      });\n      childrenSize += shard.size;\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value;\n      let flushedDir;\n\n      for await (const entry of dir.flush(blockstore)) {\n        flushedDir = entry;\n        yield flushedDir;\n      }\n\n      const label = labelPrefix + child.key;\n      links.push({\n        Name: label,\n        Tsize: flushedDir.size,\n        Hash: flushedDir.cid\n      });\n      childrenSize += flushedDir.size;\n    } else {\n      const value = child.value;\n\n      if (!value.cid) {\n        continue;\n      }\n\n      const label = labelPrefix + child.key;\n      const size = value.size;\n      links.push({\n        Name: label,\n        Tsize: size,\n        Hash: value.cid\n      });\n      childrenSize += size;\n    }\n  }\n\n  const data = Uint8Array.from(children.bitField().reverse());\n  const dir = new ipfsUnixfs.UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashCode,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  });\n  const node = {\n    Data: dir.marshal(),\n    Links: links\n  };\n  const buffer = dagPb.encode(dagPb.prepare(node));\n  const cid = await persist(buffer, blockstore, options);\n  const size = buffer.length + childrenSize;\n  yield {\n    cid,\n    unixfs: dir,\n    size\n  };\n}\n\nmodule.exports = DirSharded;","map":{"version":3,"sources":["C:/Users/user/mew-supplychain/front-end/node_modules/ipfs-unixfs-importer/cjs/src/dir-sharded.js"],"names":["dagPb","require","ipfsUnixfs","dir","persist","hamtSharding","DirSharded","constructor","props","options","_bucket","createHAMT","hashFn","hamtHashFn","bits","hamtBucketBits","put","name","value","get","childCount","leafCount","directChildrenCount","childrenCount","onlyChild","eachChildSeries","key","eachLeafSeries","child","flush","blockstore","entry","path","bucket","shardRoot","children","_children","links","childrenSize","i","length","labelPrefix","toString","toUpperCase","padStart","Bucket","shard","subShard","Error","push","Name","Tsize","size","Hash","cid","flushedDir","label","data","Uint8Array","from","bitField","reverse","UnixFS","type","fanout","tableSize","hashType","hamtHashCode","mtime","mode","node","Data","marshal","Links","buffer","encode","prepare","unixfs","module","exports"],"mappings":"AAAA;;AAEA,IAAIA,KAAK,GAAGC,OAAO,CAAC,cAAD,CAAnB;;AACA,IAAIC,UAAU,GAAGD,OAAO,CAAC,aAAD,CAAxB;;AACA,IAAIE,GAAG,GAAGF,OAAO,CAAC,UAAD,CAAjB;;AACA,IAAIG,OAAO,GAAGH,OAAO,CAAC,oBAAD,CAArB;;AACA,IAAII,YAAY,GAAGJ,OAAO,CAAC,eAAD,CAA1B;;AAEA,MAAMK,UAAN,SAAyBH,GAAzB,CAA6B;AAC3BI,EAAAA,WAAW,CAACC,KAAD,EAAQC,OAAR,EAAiB;AAC1B,UAAMD,KAAN,EAAaC,OAAb;AACA,SAAKC,OAAL,GAAeL,YAAY,CAACM,UAAb,CAAwB;AACrCC,MAAAA,MAAM,EAAEH,OAAO,CAACI,UADqB;AAErCC,MAAAA,IAAI,EAAEL,OAAO,CAACM;AAFuB,KAAxB,CAAf;AAID;;AACQ,QAAHC,GAAG,CAACC,IAAD,EAAOC,KAAP,EAAc;AACrB,UAAM,KAAKR,OAAL,CAAaM,GAAb,CAAiBC,IAAjB,EAAuBC,KAAvB,CAAN;AACD;;AACDC,EAAAA,GAAG,CAACF,IAAD,EAAO;AACR,WAAO,KAAKP,OAAL,CAAaS,GAAb,CAAiBF,IAAjB,CAAP;AACD;;AACDG,EAAAA,UAAU,GAAG;AACX,WAAO,KAAKV,OAAL,CAAaW,SAAb,EAAP;AACD;;AACDC,EAAAA,mBAAmB,GAAG;AACpB,WAAO,KAAKZ,OAAL,CAAaa,aAAb,EAAP;AACD;;AACDC,EAAAA,SAAS,GAAG;AACV,WAAO,KAAKd,OAAL,CAAac,SAAb,EAAP;AACD;;AACqB,SAAfC,eAAe,GAAG;AACvB,eAAW,MAAM;AAACC,MAAAA,GAAD;AAAMR,MAAAA;AAAN,KAAjB,IAAiC,KAAKR,OAAL,CAAaiB,cAAb,EAAjC,EAAgE;AAC9D,YAAM;AACJD,QAAAA,GADI;AAEJE,QAAAA,KAAK,EAAEV;AAFH,OAAN;AAID;AACF;;AACW,SAALW,KAAK,CAACC,UAAD,EAAa;AACvB,eAAW,MAAMC,KAAjB,IAA0BF,KAAK,CAAC,KAAKnB,OAAN,EAAeoB,UAAf,EAA2B,IAA3B,EAAiC,KAAKrB,OAAtC,CAA/B,EAA+E;AAC7E,YAAM,EACJ,GAAGsB,KADC;AAEJC,QAAAA,IAAI,EAAE,KAAKA;AAFP,OAAN;AAID;AACF;;AAtC0B;;AAwC7B,gBAAgBH,KAAhB,CAAsBI,MAAtB,EAA8BH,UAA9B,EAA0CI,SAA1C,EAAqDzB,OAArD,EAA8D;AAC5D,QAAM0B,QAAQ,GAAGF,MAAM,CAACG,SAAxB;AACA,QAAMC,KAAK,GAAG,EAAd;AACA,MAAIC,YAAY,GAAG,CAAnB;;AACA,OAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGJ,QAAQ,CAACK,MAA7B,EAAqCD,CAAC,EAAtC,EAA0C;AACxC,UAAMX,KAAK,GAAGO,QAAQ,CAAChB,GAAT,CAAaoB,CAAb,CAAd;;AACA,QAAI,CAACX,KAAL,EAAY;AACV;AACD;;AACD,UAAMa,WAAW,GAAGF,CAAC,CAACG,QAAF,CAAW,EAAX,EAAeC,WAAf,GAA6BC,QAA7B,CAAsC,CAAtC,EAAyC,GAAzC,CAApB;;AACA,QAAIhB,KAAK,YAAYvB,YAAY,CAACwC,MAAlC,EAA0C;AACxC,UAAIC,KAAJ;;AACA,iBAAW,MAAMC,QAAjB,IAA6B,MAAMlB,KAAK,CAACD,KAAD,EAAQE,UAAR,EAAoB,IAApB,EAA0BrB,OAA1B,CAAxC,EAA4E;AAC1EqC,QAAAA,KAAK,GAAGC,QAAR;AACD;;AACD,UAAI,CAACD,KAAL,EAAY;AACV,cAAM,IAAIE,KAAJ,CAAU,sDAAV,CAAN;AACD;;AACDX,MAAAA,KAAK,CAACY,IAAN,CAAW;AACTC,QAAAA,IAAI,EAAET,WADG;AAETU,QAAAA,KAAK,EAAEL,KAAK,CAACM,IAFJ;AAGTC,QAAAA,IAAI,EAAEP,KAAK,CAACQ;AAHH,OAAX;AAKAhB,MAAAA,YAAY,IAAIQ,KAAK,CAACM,IAAtB;AACD,KAdD,MAcO,IAAI,OAAOxB,KAAK,CAACV,KAAN,CAAYW,KAAnB,KAA6B,UAAjC,EAA6C;AAClD,YAAM1B,GAAG,GAAGyB,KAAK,CAACV,KAAlB;AACA,UAAIqC,UAAJ;;AACA,iBAAW,MAAMxB,KAAjB,IAA0B5B,GAAG,CAAC0B,KAAJ,CAAUC,UAAV,CAA1B,EAAiD;AAC/CyB,QAAAA,UAAU,GAAGxB,KAAb;AACA,cAAMwB,UAAN;AACD;;AACD,YAAMC,KAAK,GAAGf,WAAW,GAAGb,KAAK,CAACF,GAAlC;AACAW,MAAAA,KAAK,CAACY,IAAN,CAAW;AACTC,QAAAA,IAAI,EAAEM,KADG;AAETL,QAAAA,KAAK,EAAEI,UAAU,CAACH,IAFT;AAGTC,QAAAA,IAAI,EAAEE,UAAU,CAACD;AAHR,OAAX;AAKAhB,MAAAA,YAAY,IAAIiB,UAAU,CAACH,IAA3B;AACD,KAdM,MAcA;AACL,YAAMlC,KAAK,GAAGU,KAAK,CAACV,KAApB;;AACA,UAAI,CAACA,KAAK,CAACoC,GAAX,EAAgB;AACd;AACD;;AACD,YAAME,KAAK,GAAGf,WAAW,GAAGb,KAAK,CAACF,GAAlC;AACA,YAAM0B,IAAI,GAAGlC,KAAK,CAACkC,IAAnB;AACAf,MAAAA,KAAK,CAACY,IAAN,CAAW;AACTC,QAAAA,IAAI,EAAEM,KADG;AAETL,QAAAA,KAAK,EAAEC,IAFE;AAGTC,QAAAA,IAAI,EAAEnC,KAAK,CAACoC;AAHH,OAAX;AAKAhB,MAAAA,YAAY,IAAIc,IAAhB;AACD;AACF;;AACD,QAAMK,IAAI,GAAGC,UAAU,CAACC,IAAX,CAAgBxB,QAAQ,CAACyB,QAAT,GAAoBC,OAApB,EAAhB,CAAb;AACA,QAAM1D,GAAG,GAAG,IAAID,UAAU,CAAC4D,MAAf,CAAsB;AAChCC,IAAAA,IAAI,EAAE,wBAD0B;AAEhCN,IAAAA,IAFgC;AAGhCO,IAAAA,MAAM,EAAE/B,MAAM,CAACgC,SAAP,EAHwB;AAIhCC,IAAAA,QAAQ,EAAEzD,OAAO,CAAC0D,YAJc;AAKhCC,IAAAA,KAAK,EAAElC,SAAS,IAAIA,SAAS,CAACkC,KALE;AAMhCC,IAAAA,IAAI,EAAEnC,SAAS,IAAIA,SAAS,CAACmC;AANG,GAAtB,CAAZ;AAQA,QAAMC,IAAI,GAAG;AACXC,IAAAA,IAAI,EAAEpE,GAAG,CAACqE,OAAJ,EADK;AAEXC,IAAAA,KAAK,EAAEpC;AAFI,GAAb;AAIA,QAAMqC,MAAM,GAAG1E,KAAK,CAAC2E,MAAN,CAAa3E,KAAK,CAAC4E,OAAN,CAAcN,IAAd,CAAb,CAAf;AACA,QAAMhB,GAAG,GAAG,MAAMlD,OAAO,CAACsE,MAAD,EAAS5C,UAAT,EAAqBrB,OAArB,CAAzB;AACA,QAAM2C,IAAI,GAAGsB,MAAM,CAAClC,MAAP,GAAgBF,YAA7B;AACA,QAAM;AACJgB,IAAAA,GADI;AAEJuB,IAAAA,MAAM,EAAE1E,GAFJ;AAGJiD,IAAAA;AAHI,GAAN;AAKD;;AAED0B,MAAM,CAACC,OAAP,GAAiBzE,UAAjB","sourcesContent":["'use strict';\n\nvar dagPb = require('@ipld/dag-pb');\nvar ipfsUnixfs = require('ipfs-unixfs');\nvar dir = require('./dir.js');\nvar persist = require('./utils/persist.js');\nvar hamtSharding = require('hamt-sharding');\n\nclass DirSharded extends dir {\n  constructor(props, options) {\n    super(props, options);\n    this._bucket = hamtSharding.createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n  async put(name, value) {\n    await this._bucket.put(name, value);\n  }\n  get(name) {\n    return this._bucket.get(name);\n  }\n  childCount() {\n    return this._bucket.leafCount();\n  }\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n  async *eachChildSeries() {\n    for await (const {key, value} of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      };\n    }\n  }\n  async *flush(blockstore) {\n    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {\n      yield {\n        ...entry,\n        path: this.path\n      };\n    }\n  }\n}\nasync function* flush(bucket, blockstore, shardRoot, options) {\n  const children = bucket._children;\n  const links = [];\n  let childrenSize = 0;\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i);\n    if (!child) {\n      continue;\n    }\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n    if (child instanceof hamtSharding.Bucket) {\n      let shard;\n      for await (const subShard of await flush(child, blockstore, null, options)) {\n        shard = subShard;\n      }\n      if (!shard) {\n        throw new Error('Could not flush sharded directory, no subshard found');\n      }\n      links.push({\n        Name: labelPrefix,\n        Tsize: shard.size,\n        Hash: shard.cid\n      });\n      childrenSize += shard.size;\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value;\n      let flushedDir;\n      for await (const entry of dir.flush(blockstore)) {\n        flushedDir = entry;\n        yield flushedDir;\n      }\n      const label = labelPrefix + child.key;\n      links.push({\n        Name: label,\n        Tsize: flushedDir.size,\n        Hash: flushedDir.cid\n      });\n      childrenSize += flushedDir.size;\n    } else {\n      const value = child.value;\n      if (!value.cid) {\n        continue;\n      }\n      const label = labelPrefix + child.key;\n      const size = value.size;\n      links.push({\n        Name: label,\n        Tsize: size,\n        Hash: value.cid\n      });\n      childrenSize += size;\n    }\n  }\n  const data = Uint8Array.from(children.bitField().reverse());\n  const dir = new ipfsUnixfs.UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashCode,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  });\n  const node = {\n    Data: dir.marshal(),\n    Links: links\n  };\n  const buffer = dagPb.encode(dagPb.prepare(node));\n  const cid = await persist(buffer, blockstore, options);\n  const size = buffer.length + childrenSize;\n  yield {\n    cid,\n    unixfs: dir,\n    size\n  };\n}\n\nmodule.exports = DirSharded;\n"]},"metadata":{},"sourceType":"script"}