{"ast":null,"code":"'use strict';\n\nconst {\n  exporter,\n  recursive\n} = require('ipfs-unixfs-exporter');\n\nconst errCode = require('err-code');\n\nconst {\n  normalizeCidPath\n} = require('../utils');\n\nconst withTimeoutOption = require('ipfs-core-utils/src/with-timeout-option');\n\nconst {\n  CID\n} = require('multiformats/cid');\n\nconst {\n  pack\n} = require('it-tar');\n\nconst {\n  pipe\n} = require('it-pipe');\n\nconst {\n  gzip\n} = require('pako');\n\nconst map = require('it-map');\n\nconst toBuffer = require('it-to-buffer'); // https://www.gnu.org/software/gzip/manual/gzip.html\n\n\nconst DEFAULT_COMPRESSION_LEVEL = 6;\n/**\n * @typedef {Object} Context\n * @property {import('ipfs-repo').IPFSRepo} repo\n * @property {import('../types').Preload} preload\n *\n * @param {Context} context\n */\n\nmodule.exports = function ({\n  repo,\n  preload\n}) {\n  /**\n   * @type {import('ipfs-core-types/src/root').API[\"get\"]}\n   */\n  async function* get(ipfsPath, options = {}) {\n    if (options.compressionLevel < 0 || options.compressionLevel > 9) {\n      throw errCode(new Error('Compression level must be between 1 and 9'), 'ERR_INVALID_PARAMS');\n    }\n\n    if (options.preload !== false) {\n      let pathComponents;\n\n      try {\n        pathComponents = normalizeCidPath(ipfsPath).split('/');\n      } catch (err) {\n        throw errCode(err, 'ERR_INVALID_PATH');\n      }\n\n      preload(CID.parse(pathComponents[0]));\n    }\n\n    const ipfsPathOrCid = CID.asCID(ipfsPath) || ipfsPath;\n    const file = await exporter(ipfsPathOrCid, repo.blocks, options);\n\n    if (file.type === 'file' || file.type === 'raw') {\n      const args = [];\n\n      if (!options.compress || options.archive === true) {\n        args.push([{\n          header: {\n            name: file.path,\n            mode: file.type === 'file' && file.unixfs.mode,\n            mtime: file.type === 'file' && file.unixfs.mtime ? new Date(file.unixfs.mtime.secs * 1000) : undefined,\n            size: file.size,\n            type: 'file'\n          },\n          body: file.content()\n        }], pack(),\n        /**\n         * @param {AsyncIterable<Uint8Array>} source\n         */\n        source => map(source, buf => buf.slice()));\n      } else {\n        args.push(file.content);\n      }\n\n      if (options.compress) {\n        args.push(\n        /**\n         * @param {AsyncIterable<Uint8Array>} source\n         */\n        async function* (source) {\n          const buf = await toBuffer(source);\n          yield gzip(buf, {\n            level: options.compressionLevel || DEFAULT_COMPRESSION_LEVEL\n          });\n        });\n      } // @ts-ignore cannot derive type\n\n\n      yield* pipe(...args);\n      return;\n    }\n\n    if (file.type === 'directory') {\n      /** @type {any[]} */\n      const args = [recursive(ipfsPathOrCid, repo.blocks, options),\n      /**\n       * @param {AsyncIterable<import('ipfs-unixfs-exporter').UnixFSEntry>} source\n       */\n      async function* (source) {\n        for await (const entry of source) {\n          /** @type {import('it-tar').TarImportCandidate} */\n          const output = {\n            header: {\n              name: entry.path,\n              size: entry.size\n            }\n          };\n\n          if (entry.type === 'file') {\n            output.header.type = 'file';\n            output.header.mode = entry.unixfs.mode != null ? entry.unixfs.mode : undefined;\n            output.header.mtime = entry.unixfs.mtime ? new Date(entry.unixfs.mtime.secs * 1000) : undefined;\n            output.body = entry.content();\n          } else if (entry.type === 'raw') {\n            output.header.type = 'file';\n            output.body = entry.content();\n          } else if (entry.type === 'directory') {\n            output.header.type = 'directory';\n            output.header.mode = entry.unixfs.mode != null ? entry.unixfs.mode : undefined;\n            output.header.mtime = entry.unixfs.mtime ? new Date(entry.unixfs.mtime.secs * 1000) : undefined;\n          } else {\n            throw errCode(new Error('Not a UnixFS node'), 'ERR_NOT_UNIXFS');\n          }\n\n          yield output;\n        }\n      }, pack(),\n      /**\n       * @param {AsyncIterable<Uint8Array>} source\n       */\n      source => map(source, buf => buf.slice())];\n\n      if (options.compress) {\n        if (!options.archive) {\n          throw errCode(new Error('file is not regular'), 'ERR_INVALID_PATH');\n        }\n\n        if (options.compress) {\n          args.push(\n          /**\n           * @param {AsyncIterable<Uint8Array>} source\n           */\n          async function* (source) {\n            const buf = await toBuffer(source);\n            yield gzip(buf, {\n              level: options.compressionLevel || DEFAULT_COMPRESSION_LEVEL\n            });\n          });\n        }\n      } // @ts-ignore cannot derive type\n\n\n      yield* pipe(...args);\n      return;\n    }\n\n    throw errCode(new Error('Not a UnixFS node'), 'ERR_NOT_UNIXFS');\n  }\n\n  return withTimeoutOption(get);\n};","map":{"version":3,"sources":["C:/Users/user/mew-supplychain/front-end/node_modules/ipfs-core/src/components/get.js"],"names":["exporter","recursive","require","errCode","normalizeCidPath","withTimeoutOption","CID","pack","pipe","gzip","map","toBuffer","DEFAULT_COMPRESSION_LEVEL","module","exports","repo","preload","get","ipfsPath","options","compressionLevel","Error","pathComponents","split","err","parse","ipfsPathOrCid","asCID","file","blocks","type","args","compress","archive","push","header","name","path","mode","unixfs","mtime","Date","secs","undefined","size","body","content","source","buf","slice","level","entry","output"],"mappings":"AAAA;;AAEA,MAAM;AAAEA,EAAAA,QAAF;AAAYC,EAAAA;AAAZ,IAA0BC,OAAO,CAAC,sBAAD,CAAvC;;AACA,MAAMC,OAAO,GAAGD,OAAO,CAAC,UAAD,CAAvB;;AACA,MAAM;AAAEE,EAAAA;AAAF,IAAuBF,OAAO,CAAC,UAAD,CAApC;;AACA,MAAMG,iBAAiB,GAAGH,OAAO,CAAC,yCAAD,CAAjC;;AACA,MAAM;AAAEI,EAAAA;AAAF,IAAUJ,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAM;AAAEK,EAAAA;AAAF,IAAWL,OAAO,CAAC,QAAD,CAAxB;;AACA,MAAM;AAAEM,EAAAA;AAAF,IAAWN,OAAO,CAAC,SAAD,CAAxB;;AACA,MAAM;AAAEO,EAAAA;AAAF,IAAWP,OAAO,CAAC,MAAD,CAAxB;;AACA,MAAMQ,GAAG,GAAGR,OAAO,CAAC,QAAD,CAAnB;;AACA,MAAMS,QAAQ,GAAGT,OAAO,CAAC,cAAD,CAAxB,C,CAEA;;;AACA,MAAMU,yBAAyB,GAAG,CAAlC;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AACAC,MAAM,CAACC,OAAP,GAAiB,UAAU;AAAEC,EAAAA,IAAF;AAAQC,EAAAA;AAAR,CAAV,EAA6B;AAC5C;AACF;AACA;AACE,kBAAiBC,GAAjB,CAAsBC,QAAtB,EAAgCC,OAAO,GAAG,EAA1C,EAA8C;AAC5C,QAAIA,OAAO,CAACC,gBAAR,GAA2B,CAA3B,IAAgCD,OAAO,CAACC,gBAAR,GAA2B,CAA/D,EAAkE;AAChE,YAAMjB,OAAO,CAAC,IAAIkB,KAAJ,CAAU,2CAAV,CAAD,EAAyD,oBAAzD,CAAb;AACD;;AAED,QAAIF,OAAO,CAACH,OAAR,KAAoB,KAAxB,EAA+B;AAC7B,UAAIM,cAAJ;;AAEA,UAAI;AACFA,QAAAA,cAAc,GAAGlB,gBAAgB,CAACc,QAAD,CAAhB,CAA2BK,KAA3B,CAAiC,GAAjC,CAAjB;AACD,OAFD,CAEE,OAAOC,GAAP,EAAY;AACZ,cAAMrB,OAAO,CAACqB,GAAD,EAAM,kBAAN,CAAb;AACD;;AAEDR,MAAAA,OAAO,CAACV,GAAG,CAACmB,KAAJ,CAAUH,cAAc,CAAC,CAAD,CAAxB,CAAD,CAAP;AACD;;AAED,UAAMI,aAAa,GAAGpB,GAAG,CAACqB,KAAJ,CAAUT,QAAV,KAAuBA,QAA7C;AACA,UAAMU,IAAI,GAAG,MAAM5B,QAAQ,CAAC0B,aAAD,EAAgBX,IAAI,CAACc,MAArB,EAA6BV,OAA7B,CAA3B;;AAEA,QAAIS,IAAI,CAACE,IAAL,KAAc,MAAd,IAAwBF,IAAI,CAACE,IAAL,KAAc,KAA1C,EAAiD;AAC/C,YAAMC,IAAI,GAAG,EAAb;;AAEA,UAAI,CAACZ,OAAO,CAACa,QAAT,IAAqBb,OAAO,CAACc,OAAR,KAAoB,IAA7C,EAAmD;AACjDF,QAAAA,IAAI,CAACG,IAAL,CAAU,CAAC;AACTC,UAAAA,MAAM,EAAE;AACNC,YAAAA,IAAI,EAAER,IAAI,CAACS,IADL;AAENC,YAAAA,IAAI,EAAEV,IAAI,CAACE,IAAL,KAAc,MAAd,IAAwBF,IAAI,CAACW,MAAL,CAAYD,IAFpC;AAGNE,YAAAA,KAAK,EAAEZ,IAAI,CAACE,IAAL,KAAc,MAAd,IAAwBF,IAAI,CAACW,MAAL,CAAYC,KAApC,GAA4C,IAAIC,IAAJ,CAASb,IAAI,CAACW,MAAL,CAAYC,KAAZ,CAAkBE,IAAlB,GAAyB,IAAlC,CAA5C,GAAsFC,SAHvF;AAINC,YAAAA,IAAI,EAAEhB,IAAI,CAACgB,IAJL;AAKNd,YAAAA,IAAI,EAAE;AALA,WADC;AAQTe,UAAAA,IAAI,EAAEjB,IAAI,CAACkB,OAAL;AARG,SAAD,CAAV,EAUAvC,IAAI,EAVJ;AAWA;AACR;AACA;AACSwC,QAAAA,MAAD,IAAYrC,GAAG,CAACqC,MAAD,EAASC,GAAG,IAAIA,GAAG,CAACC,KAAJ,EAAhB,CAdf;AAgBD,OAjBD,MAiBO;AACLlB,QAAAA,IAAI,CAACG,IAAL,CACEN,IAAI,CAACkB,OADP;AAGD;;AAED,UAAI3B,OAAO,CAACa,QAAZ,EAAsB;AACpBD,QAAAA,IAAI,CAACG,IAAL;AACE;AACV;AACA;AACU,yBAAkBa,MAAlB,EAA0B;AACxB,gBAAMC,GAAG,GAAG,MAAMrC,QAAQ,CAACoC,MAAD,CAA1B;AAEA,gBAAMtC,IAAI,CAACuC,GAAD,EAAM;AACdE,YAAAA,KAAK,EAAE/B,OAAO,CAACC,gBAAR,IAA4BR;AADrB,WAAN,CAAV;AAGD,SAVH;AAYD,OAvC8C,CAyC/C;;;AACA,aAAQJ,IAAI,CAAC,GAAGuB,IAAJ,CAAZ;AAEA;AACD;;AAED,QAAIH,IAAI,CAACE,IAAL,KAAc,WAAlB,EAA+B;AAC7B;AACA,YAAMC,IAAI,GAAG,CACX9B,SAAS,CAACyB,aAAD,EAAgBX,IAAI,CAACc,MAArB,EAA6BV,OAA7B,CADE;AAEX;AACR;AACA;AACQ,uBAAkB4B,MAAlB,EAA0B;AACxB,mBAAW,MAAMI,KAAjB,IAA0BJ,MAA1B,EAAkC;AAChC;AACA,gBAAMK,MAAM,GAAG;AACbjB,YAAAA,MAAM,EAAE;AACNC,cAAAA,IAAI,EAAEe,KAAK,CAACd,IADN;AAENO,cAAAA,IAAI,EAAEO,KAAK,CAACP;AAFN;AADK,WAAf;;AAOA,cAAIO,KAAK,CAACrB,IAAN,KAAe,MAAnB,EAA2B;AACzBsB,YAAAA,MAAM,CAACjB,MAAP,CAAcL,IAAd,GAAqB,MAArB;AACAsB,YAAAA,MAAM,CAACjB,MAAP,CAAcG,IAAd,GAAqBa,KAAK,CAACZ,MAAN,CAAaD,IAAb,IAAqB,IAArB,GAA4Ba,KAAK,CAACZ,MAAN,CAAaD,IAAzC,GAAgDK,SAArE;AACAS,YAAAA,MAAM,CAACjB,MAAP,CAAcK,KAAd,GAAsBW,KAAK,CAACZ,MAAN,CAAaC,KAAb,GAAqB,IAAIC,IAAJ,CAASU,KAAK,CAACZ,MAAN,CAAaC,KAAb,CAAmBE,IAAnB,GAA0B,IAAnC,CAArB,GAAgEC,SAAtF;AACAS,YAAAA,MAAM,CAACP,IAAP,GAAcM,KAAK,CAACL,OAAN,EAAd;AACD,WALD,MAKO,IAAIK,KAAK,CAACrB,IAAN,KAAe,KAAnB,EAA0B;AAC/BsB,YAAAA,MAAM,CAACjB,MAAP,CAAcL,IAAd,GAAqB,MAArB;AACAsB,YAAAA,MAAM,CAACP,IAAP,GAAcM,KAAK,CAACL,OAAN,EAAd;AACD,WAHM,MAGA,IAAIK,KAAK,CAACrB,IAAN,KAAe,WAAnB,EAAgC;AACrCsB,YAAAA,MAAM,CAACjB,MAAP,CAAcL,IAAd,GAAqB,WAArB;AACAsB,YAAAA,MAAM,CAACjB,MAAP,CAAcG,IAAd,GAAqBa,KAAK,CAACZ,MAAN,CAAaD,IAAb,IAAqB,IAArB,GAA4Ba,KAAK,CAACZ,MAAN,CAAaD,IAAzC,GAAgDK,SAArE;AACAS,YAAAA,MAAM,CAACjB,MAAP,CAAcK,KAAd,GAAsBW,KAAK,CAACZ,MAAN,CAAaC,KAAb,GAAqB,IAAIC,IAAJ,CAASU,KAAK,CAACZ,MAAN,CAAaC,KAAb,CAAmBE,IAAnB,GAA0B,IAAnC,CAArB,GAAgEC,SAAtF;AACD,WAJM,MAIA;AACL,kBAAMxC,OAAO,CAAC,IAAIkB,KAAJ,CAAU,mBAAV,CAAD,EAAiC,gBAAjC,CAAb;AACD;;AAED,gBAAM+B,MAAN;AACD;AACF,OAjCU,EAkCX7C,IAAI,EAlCO;AAmCX;AACR;AACA;AACSwC,MAAAA,MAAD,IAAYrC,GAAG,CAACqC,MAAD,EAASC,GAAG,IAAIA,GAAG,CAACC,KAAJ,EAAhB,CAtCJ,CAAb;;AAyCA,UAAI9B,OAAO,CAACa,QAAZ,EAAsB;AACpB,YAAI,CAACb,OAAO,CAACc,OAAb,EAAsB;AACpB,gBAAM9B,OAAO,CAAC,IAAIkB,KAAJ,CAAU,qBAAV,CAAD,EAAmC,kBAAnC,CAAb;AACD;;AAED,YAAIF,OAAO,CAACa,QAAZ,EAAsB;AACpBD,UAAAA,IAAI,CAACG,IAAL;AACE;AACZ;AACA;AACY,2BAAkBa,MAAlB,EAA0B;AACxB,kBAAMC,GAAG,GAAG,MAAMrC,QAAQ,CAACoC,MAAD,CAA1B;AAEA,kBAAMtC,IAAI,CAACuC,GAAD,EAAM;AACdE,cAAAA,KAAK,EAAE/B,OAAO,CAACC,gBAAR,IAA4BR;AADrB,aAAN,CAAV;AAGD,WAVH;AAYD;AACF,OA9D4B,CAgE7B;;;AACA,aAAQJ,IAAI,CAAC,GAAGuB,IAAJ,CAAZ;AAEA;AACD;;AAED,UAAM5B,OAAO,CAAC,IAAIkB,KAAJ,CAAU,mBAAV,CAAD,EAAiC,gBAAjC,CAAb;AACD;;AAED,SAAOhB,iBAAiB,CAACY,GAAD,CAAxB;AACD,CAjJD","sourcesContent":["'use strict'\n\nconst { exporter, recursive } = require('ipfs-unixfs-exporter')\nconst errCode = require('err-code')\nconst { normalizeCidPath } = require('../utils')\nconst withTimeoutOption = require('ipfs-core-utils/src/with-timeout-option')\nconst { CID } = require('multiformats/cid')\nconst { pack } = require('it-tar')\nconst { pipe } = require('it-pipe')\nconst { gzip } = require('pako')\nconst map = require('it-map')\nconst toBuffer = require('it-to-buffer')\n\n// https://www.gnu.org/software/gzip/manual/gzip.html\nconst DEFAULT_COMPRESSION_LEVEL = 6\n\n/**\n * @typedef {Object} Context\n * @property {import('ipfs-repo').IPFSRepo} repo\n * @property {import('../types').Preload} preload\n *\n * @param {Context} context\n */\nmodule.exports = function ({ repo, preload }) {\n  /**\n   * @type {import('ipfs-core-types/src/root').API[\"get\"]}\n   */\n  async function * get (ipfsPath, options = {}) {\n    if (options.compressionLevel < 0 || options.compressionLevel > 9) {\n      throw errCode(new Error('Compression level must be between 1 and 9'), 'ERR_INVALID_PARAMS')\n    }\n\n    if (options.preload !== false) {\n      let pathComponents\n\n      try {\n        pathComponents = normalizeCidPath(ipfsPath).split('/')\n      } catch (err) {\n        throw errCode(err, 'ERR_INVALID_PATH')\n      }\n\n      preload(CID.parse(pathComponents[0]))\n    }\n\n    const ipfsPathOrCid = CID.asCID(ipfsPath) || ipfsPath\n    const file = await exporter(ipfsPathOrCid, repo.blocks, options)\n\n    if (file.type === 'file' || file.type === 'raw') {\n      const args = []\n\n      if (!options.compress || options.archive === true) {\n        args.push([{\n          header: {\n            name: file.path,\n            mode: file.type === 'file' && file.unixfs.mode,\n            mtime: file.type === 'file' && file.unixfs.mtime ? new Date(file.unixfs.mtime.secs * 1000) : undefined,\n            size: file.size,\n            type: 'file'\n          },\n          body: file.content()\n        }],\n        pack(),\n        /**\n         * @param {AsyncIterable<Uint8Array>} source\n         */\n        (source) => map(source, buf => buf.slice())\n        )\n      } else {\n        args.push(\n          file.content\n        )\n      }\n\n      if (options.compress) {\n        args.push(\n          /**\n           * @param {AsyncIterable<Uint8Array>} source\n           */\n          async function * (source) {\n            const buf = await toBuffer(source)\n\n            yield gzip(buf, {\n              level: options.compressionLevel || DEFAULT_COMPRESSION_LEVEL\n            })\n          }\n        )\n      }\n\n      // @ts-ignore cannot derive type\n      yield * pipe(...args)\n\n      return\n    }\n\n    if (file.type === 'directory') {\n      /** @type {any[]} */\n      const args = [\n        recursive(ipfsPathOrCid, repo.blocks, options),\n        /**\n         * @param {AsyncIterable<import('ipfs-unixfs-exporter').UnixFSEntry>} source\n         */\n        async function * (source) {\n          for await (const entry of source) {\n            /** @type {import('it-tar').TarImportCandidate} */\n            const output = {\n              header: {\n                name: entry.path,\n                size: entry.size\n              }\n            }\n\n            if (entry.type === 'file') {\n              output.header.type = 'file'\n              output.header.mode = entry.unixfs.mode != null ? entry.unixfs.mode : undefined\n              output.header.mtime = entry.unixfs.mtime ? new Date(entry.unixfs.mtime.secs * 1000) : undefined\n              output.body = entry.content()\n            } else if (entry.type === 'raw') {\n              output.header.type = 'file'\n              output.body = entry.content()\n            } else if (entry.type === 'directory') {\n              output.header.type = 'directory'\n              output.header.mode = entry.unixfs.mode != null ? entry.unixfs.mode : undefined\n              output.header.mtime = entry.unixfs.mtime ? new Date(entry.unixfs.mtime.secs * 1000) : undefined\n            } else {\n              throw errCode(new Error('Not a UnixFS node'), 'ERR_NOT_UNIXFS')\n            }\n\n            yield output\n          }\n        },\n        pack(),\n        /**\n         * @param {AsyncIterable<Uint8Array>} source\n         */\n        (source) => map(source, buf => buf.slice())\n      ]\n\n      if (options.compress) {\n        if (!options.archive) {\n          throw errCode(new Error('file is not regular'), 'ERR_INVALID_PATH')\n        }\n\n        if (options.compress) {\n          args.push(\n            /**\n             * @param {AsyncIterable<Uint8Array>} source\n             */\n            async function * (source) {\n              const buf = await toBuffer(source)\n\n              yield gzip(buf, {\n                level: options.compressionLevel || DEFAULT_COMPRESSION_LEVEL\n              })\n            }\n          )\n        }\n      }\n\n      // @ts-ignore cannot derive type\n      yield * pipe(...args)\n\n      return\n    }\n\n    throw errCode(new Error('Not a UnixFS node'), 'ERR_NOT_UNIXFS')\n  }\n\n  return withTimeoutOption(get)\n}\n"]},"metadata":{},"sourceType":"script"}